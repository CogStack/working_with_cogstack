{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae1fe3b4",
   "metadata": {},
   "source": [
    "### This notebook is an advanced tutorial detailing the config changes for optimising the BERT and LSTM models for Experiencer classification task on custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d58c720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import date\n",
    "from medcat.cat import CAT\n",
    "from medcat.meta_cat import MetaCAT\n",
    "from medcat.config_meta_cat import ConfigMetaCAT\n",
    "from medcat.tokenizers.meta_cat_tokenizers import TokenizerWrapperBPE, TokenizerWrapperBERT\n",
    "from tokenizers import ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca80af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to enable info level logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,force=True)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0606ec",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7a2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative path to working_with_cogstack folder\n",
    "_rel_path = os.path.join(\"..\", \"..\", \"..\")\n",
    "# absolute path to working_with_cogstack folder\n",
    "base_path = os.path.abspath(_rel_path)\n",
    "# Load mct export\n",
    "ann_dir = os.path.join(base_path, \"data\", \"medcattrainer_export\")\n",
    "\n",
    "mctrainer_export_path = ann_dir + \"\"  # name of your mct export\n",
    "\n",
    "# Load model\n",
    "model_dir = os.path.join(base_path, \"models\", \"modelpack\")\n",
    "modelpack = '' # name of modelpack\n",
    "model_pack_path = os.path.join(model_dir, modelpack)\n",
    "     #output_modelpack = model_dir + f\"{today}_trained_model\"\n",
    "\n",
    "# will be used to date the trained model\n",
    "today = str(date.today())\n",
    "today = today.replace(\"-\",\"\")\n",
    "\n",
    "# Initialise meta_ann models\n",
    "if model_pack_path[-4:] == '.zip':\n",
    "    base_dir_meta_models = model_pack_path[:-4]\n",
    "else:\n",
    "    base_dir_meta_models = model_pack_path\n",
    "\n",
    "# Iterate through the meta_models contained in the model\n",
    "meta_model_names = [] # These Meta_annotation tasks should correspond to the ones labelled in the mcttrainer export\n",
    "for dirpath, dirnames, filenames in os.walk(base_dir_meta_models):\n",
    "    for dirname in dirnames:\n",
    "        if dirname.startswith('meta_'):\n",
    "            meta_model_names.append(dirname[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aa5605",
   "metadata": {},
   "source": [
    "Before you run the next section please double check that the model meta_annotation names matches to those specified in the mct export.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699be74b",
   "metadata": {},
   "source": [
    "# Class weights "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e624d876",
   "metadata": {},
   "source": [
    "Adjusting class weights to give more importance to specific classes. Generally, class weights are used in favour of minority classes(classes with less number of samples) to boost their performance.\n",
    "<br><br>To use class weights, we have 2 options:\n",
    "<br>1. calculate class weights based on class distribution\n",
    "<br>2. using specified class weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc91f7d6",
   "metadata": {},
   "source": [
    "\n",
    "#option 1 <br>\n",
    "mc.config.train['class_weights'] = []<br>\n",
    "mc.config.train['compute_class_weights'] = True<br>\n",
    "#NOTE: this will only be applicable if mc.config.train.class_weights is empty<br>\n",
    "<br>\n",
    "#2nd option<br>\n",
    "#using specified class weights<br>\n",
    "mc.config.train['class_weights'] = [0.4,0.3,0.1]<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c217762f",
   "metadata": {},
   "source": [
    "NOTE: Make sure to correctly map the class weights to their corresponding class index (ID). <br>To check the index assigned to the classes, use: <br>`print(mc.config.general['category_value2id'])`\n",
    "<br>This will print a dictionary where the class names and their corresponding IDs (indices) are displayed. <br>\n",
    "The first position in the class weight list corresponds to the class with ID 0 in the dictionary, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3002ef0",
   "metadata": {},
   "source": [
    "# 2 phase learning for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a349af2b",
   "metadata": {},
   "source": [
    "2 phase learning is used to mitigate class imbalance. In 2 phase learning, the models are trained twice: <br> \n",
    "Phase 1: trains for minority class(es) by undersampling data so that there is no class imbalance\n",
    "<br>Phase 2: trains for all classes\n",
    "\n",
    "Phase 1 ensures that the model learns minority class(es) and captures the details correctly.\n",
    "<br> Phase 2 is when the model is expected to learn the majority class as it is trained on the entire dataset.\n",
    "\n",
    "Paper reference - https://ieeexplore.ieee.org/document/7533053\n",
    "<br>NOTE: Make sure to use class weights in favour of minority classes with 2 phase learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff613ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------Phase 1--------------------------------\n",
    "def run_phase_1(meta_model,class_wt_phase1 = None):\n",
    "    #Loading the pre-defined config for phase 1\n",
    "    config_ph_1_path = os.path.join(base_dir_meta_models,\"meta_\"+meta_model,\"config_ph1.json\")\n",
    "    with open(config_ph_1_path) as f:\n",
    "        config_ph1 = json.load(f)\n",
    "\n",
    "    mc = MetaCAT.load(save_dir_path=os.path.join(base_dir_meta_models,\"meta_\"+meta_model),config_dict = config_ph1)\n",
    "\n",
    "    if class_wt_phase1:\n",
    "        mc.config.train['class_weights'] = class_wt_phase1\n",
    "\n",
    "    mc.config.train['nepochs'] = 30 #You can change the number of epochs, remember to keep them higher for phase 1\n",
    "\n",
    "    save_dir_path= \"test_meta_\"+meta_model # Where to save the meta_model and results. \n",
    "    results = mc.train_from_json(mctrainer_export_path, save_dir_path=save_dir_path)\n",
    "    # Save results\n",
    "    json.dump(results['report'], open(os.path.join(save_dir_path,'meta_'+meta_model+'_results_phase1.json'), 'w'))\n",
    "\n",
    "#--------------------------------Phase 2--------------------------------\n",
    "def run_phase_2(meta_model,class_wt_phase2 = None): \n",
    "    #Loading the pre-defined config for phase 2\n",
    "    config_ph_2_path = os.path.join(base_dir_meta_models,\"meta_\"+meta_model,\"config_ph2.json\")\n",
    "    with open(config_ph_2_path) as f:\n",
    "        config_ph2 = json.load(f)\n",
    "\n",
    "    mc = MetaCAT.load(save_dir_path=os.path.join(base_dir_meta_models,\"meta_\"+meta_model),config_dict = config_ph2)\n",
    "\n",
    "    if class_wt_phase2:\n",
    "        mc.config.train['class_weights'] = class_wt_phase2\n",
    "\n",
    "    mc.config.train['nepochs'] = 15\n",
    "\n",
    "    save_dir_path= \"test_meta_\"+meta_model # Where to save the meta_model and results. Ensure to keep this same as Phase 1\n",
    "    results = mc.train_from_json(mctrainer_export_path, save_dir_path=save_dir_path)\n",
    "    # Save results\n",
    "    json.dump(results['report'], open(os.path.join(save_dir_path,'meta_'+meta_model+'_results_phase2.json'), 'w'))\n",
    "\n",
    "#--------------------------------Driver--------------------------------\n",
    "for meta_model in meta_model_names:\n",
    "    #To use your own class weights instead of the pre-defined ones for the 2 phases, uncomment the below lines\n",
    "    '''class_wt_phase1 = []\n",
    "    class_wt_phase2 = []'''\n",
    "\n",
    "    # Train 2 phase learning\n",
    "    logger.info(\"\\n********************Beginning Phase 1********************\")\n",
    "    run_phase_1(meta_model,class_wt_phase1)\n",
    "    logger.info(\"\\n********************Beginning Phase 2********************\")\n",
    "    run_phase_2(meta_model,class_wt_phase2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d43a3b",
   "metadata": {},
   "source": [
    "# Oversampling data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9b70b3",
   "metadata": {},
   "source": [
    "You can generate synthetic data to help mitigate class imbalance. <br> Use this code to generate synthetic data using LLM - [link](https://gist.github.com/shubham-s-agarwal/401ef8bf6cbbd66fa0c76a8fbfc1f6c4) <br> <b>NOTE</b>: the generated data will require manual quality check to ensure that high quality and relevant data is used for training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5835eb2b",
   "metadata": {},
   "source": [
    "The data generated from the gist code and the format of the data required by MedCAT are different, requiring manual formatting at the moment. We will update this module to include the code to handle the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8161b602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the training with original + synthetic data\n",
    "# Follow all the same steps till initializing the metacat model\n",
    "\n",
    "# Initialise and train meta_model\n",
    "mc = MetaCAT(tokenizer=tokenizer, embeddings=None, config=config)\n",
    "\n",
    "# the format expected is [[['text','of','the','document'], [index of medical entity], \"label\" ],\n",
    "#                ['text','of','the','document'], [index of medical entity], \"label\" ]]\n",
    "\n",
    "synthetic_data_export = [[],[],[]]\n",
    "\n",
    "results = mc.train_from_json(mctrainer_export_path, save_dir_path=save_dir_path,data_oversampled=synthetic_data_export)\n",
    "\n",
    "# Save results\n",
    "json.dump(results['report'], open(os.path.join(save_dir_path,'meta_'+meta_model+'_results.json'), 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
