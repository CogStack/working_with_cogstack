{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d58c720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import date\n",
    "from medcat.cat import CAT\n",
    "from medcat.meta_cat import MetaCAT\n",
    "from medcat.config_meta_cat import ConfigMetaCAT\n",
    "from medcat.tokenizers.meta_cat_tokenizers import TokenizerWrapperBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca80af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to enable info level logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c5b9b0",
   "metadata": {},
   "source": [
    "#### ðŸ’¡ To understand the model loading and other functionalities, please refer to the 'meta_annotation_training.ipynb' notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2c0431f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pack = '<enter path to the model pack>' # .zip model pack location\n",
    "mctrainer_export = \"<enter mct export location>\"  # name of your mct export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808c27c1",
   "metadata": {},
   "source": [
    "We won't load the models at this stage as they need to be seperately loaded later. <br> Let's check for meta models in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "675eab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the meta_models contained in the model\n",
    "meta_model_names = []\n",
    "for dirpath, dirnames, filenames in os.walk(model_pack):\n",
    "    for dirname in dirnames:\n",
    "        if dirname.startswith('meta_'):\n",
    "            meta_model_names.append(dirname[5:])\n",
    "\n",
    "print(\"Meta models:\",meta_model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e499198",
   "metadata": {},
   "source": [
    "# Class weights \n",
    "\n",
    "Adjusting class weights to give more importance to specific classes. Generally, class weights are used in favour of minority classes(classes with less number of samples) to boost their performance.\n",
    "<br><br>To use class weights, we have 2 options:\n",
    "<br>1. calculate class weights based on class distribution\n",
    "<br>2. using specified class weights\n",
    "\n",
    "\n",
    "<b>#option 1 </b><br>\n",
    "metacat.config.train['class_weights'] = []<br>\n",
    "metacat.config.train['compute_class_weights'] = True<br>\n",
    "<br>\n",
    "<b>#option 2</b><br>\n",
    "metacat.config.train['class_weights'] = [0.4,0.3,0.1]<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07f3e9",
   "metadata": {},
   "source": [
    "<b>NOTE:</b> Make sure to correctly map the class weights to their corresponding class index. <br>To check the index assigned to the classes, use: <br>`print(mc.config.general['category_value2id'])`\n",
    "<br>This will print a dictionary where the class names and their corresponding IDs (indices) are displayed. <br>\n",
    "The first position in the class weight list corresponds to the class with ID 0 in the dictionary, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a92aa60",
   "metadata": {},
   "source": [
    "# 2 phase learning for training\n",
    "\n",
    "2 phase learning is used to mitigate class imbalance. In 2 phase learning, the models are trained twice: <br> \n",
    "Phase 1: trains for minority class(es) by undersampling data so that there is no class imbalance\n",
    "<br>Phase 2: trains for all classes\n",
    "\n",
    "Phase 1 ensures that the model learns minority class(es) and captures the details correctly.\n",
    "<br> Phase 2 is when the model is expected to learn the majority class as it is trained on the entire dataset.\n",
    "\n",
    "Paper reference - https://ieeexplore.ieee.org/document/7533053\n",
    "<br>Make sure to use class weights in favour of minority classes with 2 phase learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a86b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------Phase 1--------------------------------\n",
    "def run_phase_1(meta_model,class_wt_phase1 = None):\n",
    "    #Loading the pre-defined config for phase 1\n",
    "    config_ph_1_path = os.path.join(model_pack,\"meta_\"+meta_model,\"config_ph1.json\")\n",
    "    with open(config_ph_1_path) as f:\n",
    "        config_ph1 = json.load(f)\n",
    "    mc = MetaCAT.load(save_dir_path=os.path.join(model_pack,\"meta_\"+meta_model),config_dict = config_ph1)\n",
    "\n",
    "    if class_wt_phase1:\n",
    "        mc.config.train['class_weights'] = class_wt_phase1\n",
    "\n",
    "    #You can change the number of epochs, remember to keep them higher for phase 1\n",
    "    mc.config.train['nepochs'] = 40 \n",
    "\n",
    "    results = mc.train_from_json(mctrainer_export, save_dir_path=save_dir_path)\n",
    "    # Save results\n",
    "    json.dump(results['report'], open(os.path.join(save_dir_path,'meta_'+meta_model+'_results_phase1.json'), 'w'))\n",
    "\n",
    "#--------------------------------Phase 2--------------------------------\n",
    "def run_phase_2(meta_model,class_wt_phase2 = None): \n",
    "    #Loading the pre-defined config for phase 2\n",
    "    config_ph_2_path = os.path.join(model_pack,\"meta_\"+meta_model,\"config_ph2.json\")\n",
    "    with open(config_ph_2_path) as f:\n",
    "        config_ph2 = json.load(f)\n",
    "\n",
    "    mc = MetaCAT.load(save_dir_path=os.path.join(model_pack,\"meta_\"+meta_model),config_dict = config_ph2)\n",
    "\n",
    "    if class_wt_phase2:\n",
    "        mc.config.train['class_weights'] = class_wt_phase2\n",
    "\n",
    "    #You can change the number of epochs\n",
    "    mc.config.train['nepochs'] = 20\n",
    "\n",
    "    results = mc.train_from_json(mctrainer_export, save_dir_path=save_dir_path)\n",
    "    # Save results\n",
    "    json.dump(results['report'], open(os.path.join(save_dir_path,'meta_'+meta_model+'_results_phase2.json'), 'w'))\n",
    "\n",
    "#--------------------------------Driver--------------------------------\n",
    "# Train the first meta cat model\n",
    "meta_model = meta_model_names[0]\n",
    "\n",
    "# to overwrite the existing model, resave the fine-tuned model with the same model pack dir\n",
    "meta_cat_task = meta_model\n",
    "save_dir_path = os.path.join(model_pack,\"meta_\"+ meta_cat_task)\n",
    "\n",
    "# To use your own class weights instead of the pre-defined ones for the 2 phases, put the weights in the lists below\n",
    "class_wt_phase1 = [] # Example [0.4,0.4,0.2]\n",
    "class_wt_phase2 = [] # Example [0.4,0.3,0.3]\n",
    "\n",
    "\n",
    "# Train 2 phase learning\n",
    "print(\"*** Training meta cat: \",meta_model)\n",
    "print(\"Beginning Phase 1...\")\n",
    "run_phase_1(meta_model,class_wt_phase1)\n",
    "print(\"Beginning Phase 2...\")\n",
    "run_phase_2(meta_model,class_wt_phase2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f0e878",
   "metadata": {},
   "source": [
    "# Generating synthetic data\n",
    "\n",
    "You can generate synthetic data to help mitigate class imbalance. <br> Use this code to generate synthetic data using LLM - [link](https://gist.github.com/shubham-s-agarwal/401ef8bf6cbbd66fa0c76a8fbfc1f6c4) <br> <b>NOTE</b>: the generated data will require manual quality check to ensure that high quality and relevant data is used for training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431e1002",
   "metadata": {},
   "source": [
    "The data generated from the gist code and the format of the data required by MedCAT are different, requiring manual formatting at the moment. We will update this module to include the code to handle the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d07d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the training with original + synthetic data\n",
    "# Follow all the same steps till and load the model\n",
    "\n",
    "# the format expected is [[['text','of','the','document'], [index of medical entity], \"label\" ],\n",
    "#                ['text','of','the','document'], [index of medical entity], \"label\" ]]\n",
    "\n",
    "synthetic_data_export = [[],[],[]]\n",
    "\n",
    "results = mc.train_from_json(mctrainer_export, save_dir_path=save_dir_path,data_oversampled=synthetic_data_export)\n",
    "\n",
    "# Save results\n",
    "json.dump(results['report'], open(os.path.join(save_dir_path,'meta_'+meta_model+'_results.json'), 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_medcat_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
