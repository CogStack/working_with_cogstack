{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d58c720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import date\n",
    "from medcat.cat import CAT\n",
    "from medcat.meta_cat import MetaCAT\n",
    "from medcat.config_meta_cat import ConfigMetaCAT\n",
    "from medcat.tokenizers.meta_cat_tokenizers import TokenizerWrapperBPE, TokenizerWrapperBERT\n",
    "from tokenizers import ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca80af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to enable info level logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0606ec",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7a2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative path to working_with_cogstack folder\n",
    "_rel_path = os.path.join(\"..\", \"..\", \"..\")\n",
    "# absolute path to working_with_cogstack folder\n",
    "base_path = os.path.abspath(_rel_path)\n",
    "# Load mct export\n",
    "ann_dir = os.path.join(base_path, \"data\", \"medcattrainer_export\")\n",
    "\n",
    "mctrainer_export_path = ann_dir + \"\"  # name of your mct export\n",
    "\n",
    "# Load model\n",
    "model_dir = os.path.join(base_path, \"models\", \"modelpack\")\n",
    "modelpack = '' # name of modelpack\n",
    "model_pack_path = os.path.join(model_dir, modelpack)\n",
    "     #output_modelpack = model_dir + f\"{today}_trained_model\"\n",
    "\n",
    "# will be used to date the trained model\n",
    "today = str(date.today())\n",
    "today = today.replace(\"-\",\"\")\n",
    "\n",
    "# Initialise meta_ann models\n",
    "if model_pack_path[-4:] == '.zip':\n",
    "    base_dir_meta_models = model_pack_path[:-4]\n",
    "else:\n",
    "    base_dir_meta_models = model_pack_path\n",
    "\n",
    "# Iterate through the meta_models contained in the model\n",
    "meta_model_names = [] # These Meta_annotation tasks should correspond to the ones labelled in the mcttrainer export\n",
    "for dirpath, dirnames, filenames in os.walk(base_dir_meta_models):\n",
    "    for dirname in dirnames:\n",
    "        if dirname.startswith('meta_'):\n",
    "            meta_model_names.append(dirname[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aa5605",
   "metadata": {},
   "source": [
    "Before you run the next section please double check that the model meta_annotation names matches to those specified in the mct export.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83701c19",
   "metadata": {},
   "source": [
    "# For LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1720aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for meta_model in meta_model_names:\n",
    "    vocab_file = os.path.join(base_dir_meta_models,\"meta_\"+meta_model,'bbpe-vocab.json')\n",
    "    merges_file = os.path.join(base_dir_meta_models,\"meta_\"+meta_model,'bbpe-merges.txt')\n",
    "    tokenizer = TokenizerWrapperBPE(ByteLevelBPETokenizer(vocab=vocab_file,\n",
    "                                    merges=merges_file,\n",
    "                                    lowercase=True))\n",
    "    # load and sort out the config\n",
    "    config_file = os.path.join(base_dir_meta_models,\"meta_\"+meta_model,\"config.json\")\n",
    "    with open(config_file, 'r') as jfile:\n",
    "        config_dict = json.load(jfile)\n",
    "    config = ConfigMetaCAT()\n",
    "    for key, value in config_dict.items():\n",
    "        setattr(config, key, value['py/state']['__dict__'])\n",
    "        \n",
    "    save_dir_path= \"test_meta_\"+meta_model # Where to save the meta_model and results. \n",
    "    #Ideally this should replace the meta_models inside the modelpack\n",
    "\n",
    "    # Initialise and train meta_model\n",
    "    mc = MetaCAT(tokenizer=tokenizer, embeddings=None, config=config)\n",
    "    results = mc.train_from_json(mctrainer_export_path, save_dir_path=save_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ff4e28",
   "metadata": {},
   "source": [
    "# For BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e255dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for meta_model in meta_model_names:\n",
    "    # load and sort out the config\n",
    "    config_file = os.path.join(base_dir_meta_models,\"meta_\"+meta_model,\"config.json\")\n",
    "    with open(config_file, 'r') as jfile:\n",
    "        config_dict = json.load(jfile)\n",
    "    config = ConfigMetaCAT()\n",
    "    for key, value in config_dict.items():\n",
    "        setattr(config, key, value['py/state']['__dict__'])\n",
    "\n",
    "    tokenizer = TokenizerWrapperBERT.load(os.path.join(base_dir_meta_models,\"meta_\"+meta_model), \n",
    "                                          config.model['model_variant'])\n",
    "    \n",
    "    # change model name if training BERT for the first time\n",
    "    config.model['model_name'] = 'bert'\n",
    "    \n",
    "    save_dir_path= \"test_meta_\"+meta_model # Where to save the meta_model and results. \n",
    "    #Ideally this should replace the meta_models inside the modelpack\n",
    "\n",
    "    # Initialise and train meta_model\n",
    "    mc = MetaCAT(tokenizer=tokenizer, embeddings=None, config=config)\n",
    "    results = mc.train_from_json(mctrainer_export_path, save_dir_path=save_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab23e424",
   "metadata": {},
   "source": [
    "## If you dont have the model packs, and are training from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16231060",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigMetaCAT()\n",
    "# make sure to change the following parameters:\n",
    "# config.model['nclasses']\n",
    "# config.general['category_name']\n",
    "\n",
    "# change model name if training BERT for the first time\n",
    "config.model['model_name'] = 'bert'\n",
    "\n",
    "tokenizer = TokenizerWrapperBERT.load(\"\", config.model['model_variant'])\n",
    "\n",
    "save_dir_path= \"test_meta\" # Where to save the meta_model and results. \n",
    "#Ideally this should replace the meta_models inside the modelpack\n",
    "\n",
    "# Initialise and train meta_model\n",
    "mc = MetaCAT(tokenizer=tokenizer, embeddings=None, config=config)\n",
    "results = mc.train_from_json(mctrainer_export_path, save_dir_path=save_dir_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
