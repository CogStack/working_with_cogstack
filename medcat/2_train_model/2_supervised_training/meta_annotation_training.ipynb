{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import date\n",
    "from medcat.cat import CAT\n",
    "from medcat.components.addons.meta_cat.meta_cat import MetaCATAddon\n",
    "from medcat.config.config_meta_cat import ConfigMetaCAT\n",
    "from medcat.components.addons.meta_cat.mctokenizers.bpe_tokenizer import TokenizerWrapperBPE\n",
    "from medcat.components.addons.meta_cat.mctokenizers.bert_tokenizer import TokenizerWrapperBERT\n",
    "from medcat.utils.legacy.identifier import is_legacy_model_pack\n",
    "from medcat.storage.serialisers import deserialise\n",
    "from medcat.tokenizing.tokenizers import create_tokenizer\n",
    "from tokenizers import ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca80af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to enable info level logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO,force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0606ec",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7a2e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative path to working_with_cogstack folder\n",
    "_rel_path = os.path.join(\"..\", \"..\", \"..\")\n",
    "# absolute path to working_with_cogstack folder\n",
    "base_path = os.path.abspath(_rel_path)\n",
    "# Load mct export\n",
    "ann_dir = os.path.join(base_path, \"data\", \"medcattrainer_export\")\n",
    "\n",
    "mctrainer_export_path = ann_dir + \"\"  # name of your mct export\n",
    "\n",
    "# Load model\n",
    "model_dir = os.path.join(base_path, \"models\", \"modelpack\")\n",
    "modelpack = '' # name of modelpack\n",
    "model_pack_path = os.path.join(model_dir, modelpack)\n",
    "     #output_modelpack = model_dir + f\"{today}_trained_model\"\n",
    "\n",
    "# will be used to date the trained model\n",
    "today = str(date.today())\n",
    "today = today.replace(\"-\",\"\")\n",
    "\n",
    "# Initialise meta_ann models\n",
    "if model_pack_path[-4:] == '.zip':\n",
    "    base_dir_meta_models = model_pack_path[:-4]\n",
    "else:\n",
    "    base_dir_meta_models = model_pack_path\n",
    "\n",
    "# Iterate through the meta_models contained in the model\n",
    "meta_model_names = [] # These Meta_annotation tasks should correspond to the ones labelled in the mcttrainer export\n",
    "model_is_legacy = is_legacy_model_pack(base_dir_meta_models)\n",
    "if model_is_legacy:\n",
    "    # NOTE: when loaded, will be auto-converted\n",
    "    exp_start = \"meta_\"\n",
    "    config_path = [\"config.json\"]\n",
    "else:\n",
    "    exp_start = \"addon_meta_cat\"\n",
    "    base_dir_meta_models = os.path.join(base_dir_meta_models, \"saved_components\")\n",
    "    config_path = [\"meta_cat\", \"config\"]\n",
    "for dirpath, dirnames, filenames in os.walk(base_dir_meta_models):\n",
    "    for dirname in dirnames:\n",
    "        if dirname.startswith(exp_start):\n",
    "            meta_model_names.append(dirname[len(exp_start):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aa5605",
   "metadata": {},
   "source": [
    "Before you run the next section please double check that the model meta_annotation names matches to those specified in the mct export.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf6f5c3",
   "metadata": {},
   "source": [
    "Depending on the model pack you have, please run the LSTM model or BERT model section. <br>\n",
    "If you are unsure, use this section to check the model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2933f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for meta_model in meta_model_names:\n",
    "    config_path = os.path.join(base_dir_meta_models, exp_start + meta_model, *config_path)\n",
    "    if model_is_legacy:\n",
    "        with open(config_path, 'r') as jfile:\n",
    "            config_dict = json.load(jfile)\n",
    "        print(f\"Model used for meta_{meta_model}:\", config_dict['model']['model_name'])\n",
    "    else:\n",
    "        cnf: ConfigMetaCAT = deserialise(config_path)\n",
    "        print(f\"Model used for meta_{meta_model}:\", config_dict.model.model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83701c19",
   "metadata": {},
   "source": [
    "# For LSTM and BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1720aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we need to provide a BaseTokenizer to add the relevant additional data paths\n",
    "#       to the relevant Entity/Span and Document implementation\n",
    "#       we'll use the regex tokenizer here for example since it's easier to initialise\n",
    "#       but you can use a spacy-based one, you just need to also pass:\n",
    "#       - the model name (e.g 'en_core_web_md')\n",
    "#       - the names of the disabled components (e.g ['ner', 'parser', 'vectors', 'textcat',\n",
    "#           'entity_linker', 'sentencizer', 'entity_ruler', 'merge_noun_chunks', 'merge_entities', 'merge_subtokens'])\n",
    "#       - whether diacritics should be used\n",
    "#       - max document length (e.g 1_000_000)\n",
    "base_tokenizer = create_tokenizer(\"regex\")\n",
    "for meta_model in meta_model_names:\n",
    "    meta_cat_path = os.path.join(base_dir_meta_models, exp_start + meta_model)\n",
    "    if model_is_legacy:\n",
    "        from medcat.utils.legacy.convert_meta_cat import get_meta_cat_from_old\n",
    "        meta_cat: MetaCATAddon = get_meta_cat_from_old(meta_cat_path, base_tokenizer)\n",
    "    else:\n",
    "        # NOTE: the expected workflow when loading the model\n",
    "        #       is one where the config is stored as part of the overall config\n",
    "        #       and thus using it for loading is trivial\n",
    "        #       but here we need to manually load the config from disk\n",
    "        cnf_path = os.path.join(meta_cat_path, \"config\")\n",
    "        cnf: ConfigMetaCAT = deserialise(cnf_path)\n",
    "        # load the meta_model\n",
    "        meta_cat = MetaCATAddon.load_existing(cnf, base_tokenizer, os.path.join(base_dir_meta_models, exp_start + meta_model))\n",
    "    mc = meta_cat.mc\n",
    "\n",
    "    # changing parameters\n",
    "    mc.config.train.nepochs = 15\n",
    "\n",
    "    save_dir_path= \"test_meta_\"+meta_model # Where to save the meta_model and results. \n",
    "    #Ideally this should replace the meta_models inside the modelpack\n",
    "\n",
    "    # train the meta_model\n",
    "    results = mc.train_from_json(mctrainer_export_path, save_dir_path=save_dir_path)\n",
    "    \n",
    "    # Save results\n",
    "    json.dump(results['report'], open(os.path.join(save_dir_path,'meta_'+meta_model+'_results.json'), 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab23e424",
   "metadata": {},
   "source": [
    "## If you dont have the model packs, and are training from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16231060",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigMetaCAT()\n",
    "# make sure to change the following parameters:\n",
    "# config.model['nclasses']\n",
    "# config.general['category_name']\n",
    "\n",
    "# change model name if training BERT for the first time\n",
    "config.model.model_name = 'bert'\n",
    "\n",
    "save_dir_path= \"test_meta\" # Where to save the meta_model and results. \n",
    "#Ideally this should replace the meta_models inside the modelpack\n",
    "\n",
    "# NOTE: we need to provide a BaseTokenizer to add the relevant additional data paths\n",
    "#       to the relevant Entity/Span and Document implementation\n",
    "#       we'll use the regex tokenizer here for example since it's easier to initialise\n",
    "#       but you can use a spacy-based one, you just need to also pass:\n",
    "#       - the model name (e.g 'en_core_web_md')\n",
    "#       - the names of the disabled components (e.g ['ner', 'parser', 'vectors', 'textcat',\n",
    "#           'entity_linker', 'sentencizer', 'entity_ruler', 'merge_noun_chunks', 'merge_entities', 'merge_subtokens'])\n",
    "#       - whether diacritics should be used\n",
    "#       - max document length (e.g 1_000_000)\n",
    "base_tokenizer = create_tokenizer(\"regex\")\n",
    "\n",
    "# Initialise and train meta_model\n",
    "mc = MetaCATAddon.create_new(config, base_tokenizer)\n",
    "results = mc.mc.train_from_json(mctrainer_export_path, save_dir_path=save_dir_path)\n",
    "\n",
    "# Save results\n",
    "json.dump(results['report'], open(os.path.join(save_dir_path,'meta_'+meta_model+'_results.json'), 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
